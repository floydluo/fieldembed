{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORPUS\tread from pickle file : data/WikiTotal/word/Token447170/Pyramid/CORPUS.p\n",
      "CORPUS\tthe length of it is   : 1\n",
      "FOLDER\tread from pickle file : data/WikiTotal/word/Token447170/Pyramid/FOLDER.p\n",
      "FOLDER\tthe length of it is   : 1\n",
      "TEXT\tread from pickle file : data/WikiTotal/word/Token447170/Pyramid/TEXT.p\n",
      "TEXT\tthe length of it is   : 4717592\n",
      "SENT\tread from pickle file : data/WikiTotal/word/Token447170/Pyramid/SENT.p\n",
      "SENT\tthe length of it is   : 11199643\n",
      "TOKEN\tread from pickle file : data/WikiTotal/word/Token447170/Pyramid/TOKEN.p\n",
      "TOKEN\tthe length of it is   : 257789077\n",
      "**************************************** \n",
      "\n",
      "token\tread from pickle file : data/WikiTotal/word/Token447170/GrainUnique/token.voc\n",
      "token\tthe length of it is   : 447170\n",
      "**************************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from nlptext.base import BasicObject\n",
    "from datetime import datetime\n",
    "\n",
    "from fieldembed.models.fieldembed import FieldEmbedding\n",
    "\n",
    "\n",
    "BOB = 'data/WikiTotal/word/Token447170/Pyramid/'\n",
    "LGU = 'data/WikiTotal/word/Token447170/GrainUnique/'\n",
    "\n",
    "BasicObject.INIT_FROM_PICKLE(BOB, LGU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deal with the Channel: token\n",
      "Current Channel is        \t token\n",
      "Current Channel Max_Ngram \t 1\n",
      "Deal with the Channel: char\n",
      "Current Channel is        \t char\n",
      "Current Channel Max_Ngram \t 1\n",
      "Deal with the Channel: pinyin\n",
      "Current Channel is        \t pinyin\n",
      "Current Channel Max_Ngram \t 2\n",
      "Deal with the Channel: subcomp\n",
      "Current Channel is        \t subcomp\n",
      "Current Channel Max_Ngram \t 3\n",
      "Deal with the Channel: stroke\n",
      "Current Channel is        \t stroke\n",
      "Current Channel Max_Ngram \t 3\n"
     ]
    }
   ],
   "source": [
    "CHANNEL_SETTINGS_TEMPLATE = {\n",
    "    # CTX_IND\n",
    "    'token':   {'use': True, 'Max_Ngram': 1,},\n",
    "    'char':    {'use': True,'Max_Ngram': 1, 'end_grain': False},\n",
    "    'pinyin':  {'use': True,'Max_Ngram': 2, 'end_grain': False},\n",
    "    'subcomp': {'use': True,'Max_Ngram': 3, 'end_grain': True},\n",
    "    'stroke':  {'use': True,'Max_Ngram': 3, 'end_grain': True},\n",
    "    # 'pos':     {'use': True,'Max_Ngram': 3, 'end_grain': True},\n",
    "}\n",
    "\n",
    "BasicObject.BUILD_GRAIN_UNI_AND_LOOKUP(CHANNEL_SETTINGS_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++Start++++++ 2019-06-21 21:44:05.852812\n",
      "-------> Prepare Field Info....\n",
      "Get LookUp Table for Channel: char\n",
      "Get LookUp Table for Channel: pinyin2\n",
      "Get LookUp Table for Channel: stroke3e\n",
      "use_head: 1 use_sub: 4 use_hyper: 0\n",
      "!!!======== Build_vocab based on NLPText....\n",
      "-------> Prepare Vocab....\n",
      "o--> Get Vocab Frequency from NLPText\n",
      "o--> Prepare WV's index2word, vocab...\n",
      "\tStart:  2019-06-21 21:44:10.786890\n",
      "\tEnd  :  2019-06-21 21:44:11.838129\n",
      "\tTotal Time: 0:00:01.051239\n",
      "o--> Compute Token's sampel_int...\n",
      "\tStart:  2019-06-21 21:44:11.838318\n",
      "\tEnd  :  2019-06-21 21:44:12.747151\n",
      "\tTotal Time: 0:00:00.908833\n",
      "o--> Compute Cum Table\n",
      "\tStart:  2019-06-21 21:44:12.747491\n",
      "\tEnd  :  2019-06-21 21:44:13.378052\n",
      "\tTotal Time: 0:00:00.630561\n",
      "-------> Prepare Trainable Weight....\n",
      "o--> Prepare Trainable Parameters\n",
      "\tStart:  2019-06-21 21:44:13.378638\n",
      "Init syn1neg with zeros\n",
      "token (447170, 200)\n",
      "char (7049, 200)\n",
      "pinyin (10336, 200)\n",
      "subcomp (73622, 200)\n",
      "stroke (4975, 200)\n",
      "use_head: 1 use_sub: 4\n",
      "\tEnd  :  2019-06-21 21:44:17.929597\n",
      "\tTotal Time: 0:00:04.550959\n",
      "======== The Voc and Parameters are Ready!\n",
      "======== Total Time:  0:00:07.146057\n",
      "finish build vocab\n",
      "\n",
      "\n",
      "======== Training Start ....\n",
      "257789077\n",
      "Start getting batch infos\n",
      "2019-06-21 21:44:17.929877\n",
      "Read info from: data/WikiTotal/word/Token447170/Pyramid/10000_Info.p\n",
      "2019-06-21 21:44:17.946375\n",
      "The time of finding batch_end_st_idx_list: 0:00:00.016498\n",
      "Total job number is: 25779\n",
      "======== Training End ......\n",
      "======== Total Time:  0:47:00.642896\n",
      "+++++End++++++ 2019-06-21 22:31:18.610309 Using: 0:47:12.757497\n"
     ]
    }
   ],
   "source": [
    "mode =  'train_batch_fieldembed_negsamp'\n",
    "workers = 8\n",
    "size = 200\n",
    "batch_words = 10000\n",
    "alpha = 0.025\n",
    "sg = 1\n",
    "iter = 1\n",
    "train = True\n",
    "\n",
    "sg_or_cbow = 'sg' if sg else 'cbow'\n",
    "\n",
    "s = datetime.now(); print('+++++Start++++++', s)\n",
    "# end = datetime.now(); print('+++++End++++++', end, 'Using:',e - s ); \n",
    "model = FieldEmbedding(nlptext = BasicObject, Field_Settings= BasicObject.CHANNEL_SETTINGS, \n",
    "                       size = size, train = train, alpha = alpha, mode = mode,\n",
    "                       sg = sg, iter=iter, workers = workers, batch_words = batch_words)\n",
    "e = datetime.now(); time = e - s\n",
    "print('+++++End++++++', e, 'Using:', time); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/floydluo/Desktop/new_nlp/fieldembed/models/keyedvectors.py:1306: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return (m / dist).astype(REAL)\n",
      "/home/floydluo/Desktop/new_nlp/fieldembed/models/keyedvectors.py:1306: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (m / dist).astype(REAL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:16.826184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sim240_spearman': 0.1409355711758599,\n",
       " 'sim297_spearman': 0.30566925028231084,\n",
       " 'ana_capital-common-countries': 0.11038961038961038,\n",
       " 'ana_city-in-state': 0.2,\n",
       " 'ana_family': 0.3235294117647059,\n",
       " 'ana_Total accuracy': 0.19141914191419143,\n",
       " 'time': datetime.timedelta(seconds=2832, microseconds=757497)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sg\n",
    "from evals import Evaluation\n",
    "wv = model.wv_neg\n",
    "evals = Evaluation(wv)\n",
    "\n",
    "s = datetime.now()\n",
    "d = evals.run_wv_lexical_evals()\n",
    "d['time'] = time\n",
    "e = datetime.now()\n",
    "print(e - s)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:17.617023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sim240_spearman': 0.5477665287852213,\n",
       " 'sim297_spearman': 0.6157023344839415,\n",
       " 'ana_capital-common-countries': 0.670995670995671,\n",
       " 'ana_city-in-state': 0.7085714285714285,\n",
       " 'ana_family': 0.4852941176470588,\n",
       " 'ana_Total accuracy': 0.6226622662266227,\n",
       " 'time': datetime.timedelta(seconds=2832, microseconds=757497)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sg\n",
    "from evals import Evaluation\n",
    "wv = model.wv\n",
    "evals = Evaluation(wv)\n",
    "\n",
    "s = datetime.now()\n",
    "d = evals.run_wv_lexical_evals()\n",
    "d['time'] = time\n",
    "e = datetime.now()\n",
    "print(e - s)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2832 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token': <fieldembed.models.keyedvectors.Word2VecKeyedVectors at 0x7f2771ae4710>,\n",
       " 'char': <fieldembed.models.keyedvectors.Word2VecKeyedVectors at 0x7f27761538d0>,\n",
       " 'pinyin': <fieldembed.models.keyedvectors.Word2VecKeyedVectors at 0x7f27a7518f28>,\n",
       " 'subcomp': <fieldembed.models.keyedvectors.Word2VecKeyedVectors at 0x7f26d4a402b0>,\n",
       " 'stroke': <fieldembed.models.keyedvectors.Word2VecKeyedVectors at 0x7f26d3ebab38>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/T_C_p_s_s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/floydluo/Desktop/new_nlp/fieldembed/models/keyedvectors.py:1306: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return (m / dist).astype(REAL)\n",
      "/home/floydluo/Desktop/new_nlp/fieldembed/models/keyedvectors.py:1306: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (m / dist).astype(REAL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:17.787337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sim240_spearman': 0.46059041918382465,\n",
       " 'sim297_spearman': 0.5528196341983667,\n",
       " 'ana_capital-common-countries': 0.23593073593073594,\n",
       " 'ana_city-in-state': 0.2914285714285714,\n",
       " 'ana_family': 0.43014705882352944,\n",
       " 'ana_Total accuracy': 0.3047304730473047,\n",
       " 'time': datetime.timedelta(seconds=613, microseconds=795191)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cbow\n",
    "from evals import Evaluation\n",
    "wv = model.wv_neg\n",
    "evals = Evaluation(wv)\n",
    "\n",
    "s = datetime.now()\n",
    "d = evals.run_wv_lexical_evals()\n",
    "d['time'] = time\n",
    "e = datetime.now()\n",
    "print(e - s)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:18.607856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sim240_spearman': 0.4436952827120671,\n",
       " 'sim297_spearman': 0.5474221275619056,\n",
       " 'ana_capital-common-countries': 0.23593073593073594,\n",
       " 'ana_city-in-state': 0.22285714285714286,\n",
       " 'ana_family': 0.4117647058823529,\n",
       " 'ana_Total accuracy': 0.28602860286028603,\n",
       " 'time': datetime.timedelta(seconds=613, microseconds=795191)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cbow\n",
    "from evals import Evaluation\n",
    "wv = model.wv\n",
    "evals = Evaluation(wv)\n",
    "\n",
    "s = datetime.now()\n",
    "d = evals.run_wv_lexical_evals()\n",
    "d['time'] = time\n",
    "e = datetime.now()\n",
    "print(e - s)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FieldEmbedding.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sim240_spearman': 0.4596847078345505,\n",
       " 'sim297_spearman': 0.5696404402400501,\n",
       " 'ana_capital-common-countries': 0.47835497835497837,\n",
       " 'ana_city-in-state': 0.46285714285714286,\n",
       " 'ana_family': 0.5404411764705882,\n",
       " 'ana_Total accuracy': 0.49394939493949397,\n",
       " 'time': datetime.timedelta(seconds=1053, microseconds=431700)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sg\n",
    "from evals import Evaluation\n",
    "wv = model.wv_neg\n",
    "evals = Evaluation(wv)\n",
    "\n",
    "s = datetime.now()\n",
    "d = evals.run_wv_lexical_evals()\n",
    "d['time'] = time\n",
    "e = datetime.now()\n",
    "print(e - s)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:17.665273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sim240_spearman': 0.5124129038872299,\n",
       " 'sim297_spearman': 0.6042667242353106,\n",
       " 'ana_capital-common-countries': 0.645021645021645,\n",
       " 'ana_city-in-state': 0.7142857142857143,\n",
       " 'ana_family': 0.4963235294117647,\n",
       " 'ana_Total accuracy': 0.6138613861386139,\n",
       " 'time': datetime.timedelta(seconds=1053, microseconds=431700)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sg\n",
    "from evals import Evaluation\n",
    "wv = model.wv\n",
    "evals = Evaluation(wv)\n",
    "\n",
    "s = datetime.now()\n",
    "d = evals.run_wv_lexical_evals()\n",
    "d['time'] = time\n",
    "e = datetime.now()\n",
    "print(e - s)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
