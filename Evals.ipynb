{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evals Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T02:44:22.688013Z",
     "start_time": "2019-08-27T02:44:20.038697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORPUS\tread from pickle file : data/fudan/word/Pyramid/CORPUS.p\n",
      "CORPUS\tthe length of it is   : 1\n",
      "GROUP\tread from pickle file : data/fudan/word/Pyramid/GROUP.p\n",
      "GROUP\tthe length of it is   : 5\n",
      "TEXT\tread from pickle file : data/fudan/word/Pyramid/TEXT.p\n",
      "TEXT\tthe length of it is   : 5885\n",
      "SENT\tread from pickle file : data/fudan/word/Pyramid/SENT.p\n",
      "SENT\tthe length of it is   : 5885\n",
      "TOKEN\tread from pickle file : data/fudan/word/Pyramid/TOKEN.p\n",
      "TOKEN\tthe length of it is   : 17252831\n",
      "**************************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from fieldembed.keyedvectors import KeyedVectors\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "from nlptext.sentence import Sentence\n",
    "from nlptext.base import BasicObject\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "Data_Dir = 'data/fudan/word/'\n",
    "BasicObject.INIT_FROM_PICKLE(Data_Dir)\n",
    "nlptext = BasicObject\n",
    "\n",
    "\n",
    "def getsent2matrix(sent, wv):\n",
    "    token_strs = [i[0] for i in sent.get_grain_str('token')]\n",
    "    wv = wv.derivative_wv\n",
    "    wv.set_GU_and_TU()\n",
    "    TU = wv.TU # LGU in derivative wv is LTU\n",
    "    if TU is None:\n",
    "        TU = wv.GU\n",
    "    # this code is verbose\n",
    "    # TODO: how to deal with unk tokens\n",
    "    token_idxes = [TU[1].get(token_str) for token_str in token_strs if token_str in TU[1]] # 0 is not unk, to fix it in the future\n",
    "    # token_idxes = [i[0] for i in token_idxes]\n",
    "    # print(token_idxes)\n",
    "    # print(token_idxes)\n",
    "    matrix = wv.vectors[token_idxes]\n",
    "    return matrix\n",
    "\n",
    "def convert_document_to_X_and_Y(nlptext, wv):\n",
    "    doc_num = nlptext.SENT['length']\n",
    "    \n",
    "    docmatrix = np.zeros((doc_num, wv.vector_size))\n",
    "    labels = np.zeros(doc_num, dtype = int)\n",
    "    \n",
    "    for sentidx in range(doc_num):\n",
    "        sent = Sentence(sentidx)\n",
    "        matrix = getsent2matrix(sent, wv)\n",
    "        # matrix.append(sent)\n",
    "        docvector = np.mean(matrix, axis = 0)\n",
    "        docmatrix[sentidx] = docvector\n",
    "        labels[sentidx] = sent.IdxGroup\n",
    "    return docmatrix, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T02:44:22.706511Z",
     "start_time": "2019-08-27T02:44:22.689512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['embeddings/baseline/WikiChinese/word/word2vec/sg-it1-w5-ng10-lr0.025-smp0.001-nsexp0.75-th4/word200',\n",
       " 'embeddings/baseline/WikiChinese/word/word2vec/cb-it1-w5-ng10-lr0.025-smp0.001-nsexp0.75-th4/word200',\n",
       " 'embeddings/baseline/WikiChinese/word/cwe/cb-it1-w5-ng10-lr0.025-smp0.001-nsexp0.75-th4/word200',\n",
       " 'embeddings/baseline/WikiChinese/word/jwe/cb-it1-w5-ng10-lr0.025-smp0.001-nsexp0.75-th4/word200']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "base_dir = 'embeddings/baseline/'\n",
    "\n",
    "def EmbeddingModelsReader(base_dir):\n",
    "    results = [x for x in os.walk(base_dir) if x[2]]\n",
    "    d = {i[0]: i[2] for i in results}\n",
    "    L = []\n",
    "    for path, names in d.items():\n",
    "        for name in names:\n",
    "            if 'word' in name:\n",
    "                modelname = os.path.join(path, name)\n",
    "                L.append(modelname)\n",
    "                # print(modelname)\n",
    "    return L\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "modelnames = EmbeddingModelsReader(base_dir)\n",
    "modelnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T02:47:39.601908Z",
     "start_time": "2019-08-27T02:47:39.599027Z"
    }
   },
   "outputs": [],
   "source": [
    "D = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T02:56:54.782234Z",
     "start_time": "2019-08-27T02:48:19.534141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings/baseline/WikiChinese/word/word2vec/sg-it1-w5-ng10-lr0.025-smp0.001-nsexp0.75-th4/word200\n",
      "390106 200\n",
      "\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "0.8465458663646659\n",
      "[[337  13  10  16   1]\n",
      " [ 12 281   2  25   7]\n",
      " [  6   0 288  19   0]\n",
      " [  4   3  28 401  12]\n",
      " [  2  25   2  84 188]]\n",
      "0.8637169386015764\n",
      "0.011571134764834078\n",
      "{'sim240_spearman': 0.5101948970523248, 'sim297_spearman': 0.5929414085454954, 'ana_capital-common-countries': 0.6936758893280632, 'ana_city-in-state': 0.7314285714285714, 'ana_family': 0.48161764705882354, 'ana_Total accuracy': 0.640083945435467, 'cls_score_mean': 0.8637169386015764, 'cls_score_2std': 0.011571134764834078}\n",
      "embeddings/baseline/WikiChinese/word/word2vec/cb-it1-w5-ng10-lr0.025-smp0.001-nsexp0.75-th4/word200\n",
      "390106 200\n",
      "\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "0.9280860702151755\n",
      "[[363   5   8   1   0]\n",
      " [  5 312   2   5   3]\n",
      " [  7   0 288  18   0]\n",
      " [  4   1  12 417  14]\n",
      " [  0  14   0  28 259]]\n",
      "0.9277818131896162\n",
      "0.010382401094377349\n",
      "{'sim240_spearman': 0.4590138361504972, 'sim297_spearman': 0.5722940705432882, 'ana_capital-common-countries': 0.5889328063241107, 'ana_city-in-state': 0.4342857142857143, 'ana_family': 0.4963235294117647, 'ana_Total accuracy': 0.534102833158447, 'cls_score_mean': 0.9277818131896162, 'cls_score_2std': 0.010382401094377349}\n",
      "embeddings/baseline/WikiChinese/word/cwe/cb-it1-w5-ng10-lr0.025-smp0.001-nsexp0.75-th4/word200\n",
      "390106\t200\n",
      "\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "0.9490373725934315\n",
      "[[367   0   8   1   1]\n",
      " [  2 318   1   1   5]\n",
      " [  4   0 292  17   0]\n",
      " [  4   0   7 423  14]\n",
      " [  0   9   1  15 276]]\n",
      "0.9456220766394043\n",
      "0.011157100567962422\n",
      "{'sim240_spearman': 0.5049033964108451, 'sim297_spearman': 0.5378947334991742, 'ana_capital-common-countries': 0.08695652173913043, 'ana_city-in-state': 0.04, 'ana_family': 0.16911764705882354, 'ana_Total accuracy': 0.10178384050367262, 'cls_score_mean': 0.9456220766394043, 'cls_score_2std': 0.011157100567962422}\n",
      "embeddings/baseline/WikiChinese/word/jwe/cb-it1-w5-ng10-lr0.025-smp0.001-nsexp0.75-th4/word200\n",
      "390106 200\n",
      "\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "0.8912797281993206\n",
      "[[350  12   8   6   1]\n",
      " [  8 303   2   8   6]\n",
      " [ 10   0 284  19   0]\n",
      " [  4   2  19 406  17]\n",
      " [  1  25   2  42 231]]\n",
      "0.8978711875503016\n",
      "0.009953550071565268\n",
      "{'sim240_spearman': 0.47719323294692895, 'sim297_spearman': 0.5831517843480724, 'ana_capital-common-countries': 0.3774703557312253, 'ana_city-in-state': 0.44, 'ana_family': 0.4338235294117647, 'ana_Total accuracy': 0.4050367261280168, 'cls_score_mean': 0.8978711875503016, 'cls_score_2std': 0.009953550071565268}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for wv_file in modelnames:\n",
    "    # 1. load data\n",
    "    if wv_file in D: continue \n",
    "    print(wv_file)\n",
    "    sep = ' ' if 'cwe' not in wv_file else '\\t'\n",
    "    word_vec = KeyedVectors.load_word2vec_format(wv_file, sep = sep)\n",
    " \n",
    "    # 2. lexical evals\n",
    "    evals_result = word_vec.lexical_evals()\n",
    "    \n",
    "    # 3. sent clf\n",
    "    docmatrix, labels = convert_document_to_X_and_Y(nlptext, word_vec)\n",
    "    X = docmatrix\n",
    "    Y = labels\n",
    "\n",
    "    # 70% training and 30% testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 109)\n",
    "\n",
    "    # clf = svm.SVC(kernel = 'linear')\n",
    "    clf = svm.SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape=None, degree=3,\n",
    "                  gamma='auto', kernel='rbf', max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "                  tol=0.001, verbose=False)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(clf)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    scores = cross_val_score(clf, X, Y, cv = 5)\n",
    "    print(scores.mean())\n",
    "    print(scores.std() * 2)\n",
    "\n",
    "    evals_result['cls_score_mean'] = scores.mean()\n",
    "    evals_result['cls_score_2std'] = scores.std() * 2\n",
    "    D[wv_file] = evals_result\n",
    "    print(evals_result)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T03:08:10.000030Z",
     "start_time": "2019-08-27T03:08:09.980527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sim240_spearman</th>\n",
       "      <th>sim297_spearman</th>\n",
       "      <th>ana_Total accuracy</th>\n",
       "      <th>cls_score_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>embeddings/baseline/WikiChinese/word/word2vec/sg-it1-w5-ng10-lr0.025-smp0.001-nsexp0.75-th4/word200</th>\n",
       "      <td>0.510195</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>0.640084</td>\n",
       "      <td>0.863717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embeddings/baseline/WikiChinese/word/word2vec/cb-it1-w5-ng10-lr0.025-smp0.001-nsexp0.75-th4/word200</th>\n",
       "      <td>0.459014</td>\n",
       "      <td>0.572294</td>\n",
       "      <td>0.534103</td>\n",
       "      <td>0.927782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embeddings/baseline/WikiChinese/word/cwe/cb-it1-w5-ng10-lr0.025-smp0.001-nsexp0.75-th4/word200</th>\n",
       "      <td>0.504903</td>\n",
       "      <td>0.537895</td>\n",
       "      <td>0.101784</td>\n",
       "      <td>0.945622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embeddings/baseline/WikiChinese/word/jwe/cb-it1-w5-ng10-lr0.025-smp0.001-nsexp0.75-th4/word200</th>\n",
       "      <td>0.477193</td>\n",
       "      <td>0.583152</td>\n",
       "      <td>0.405037</td>\n",
       "      <td>0.897871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    sim240_spearman  \\\n",
       "embeddings/baseline/WikiChinese/word/word2vec/s...         0.510195   \n",
       "embeddings/baseline/WikiChinese/word/word2vec/c...         0.459014   \n",
       "embeddings/baseline/WikiChinese/word/cwe/cb-it1...         0.504903   \n",
       "embeddings/baseline/WikiChinese/word/jwe/cb-it1...         0.477193   \n",
       "\n",
       "                                                    sim297_spearman  \\\n",
       "embeddings/baseline/WikiChinese/word/word2vec/s...         0.592941   \n",
       "embeddings/baseline/WikiChinese/word/word2vec/c...         0.572294   \n",
       "embeddings/baseline/WikiChinese/word/cwe/cb-it1...         0.537895   \n",
       "embeddings/baseline/WikiChinese/word/jwe/cb-it1...         0.583152   \n",
       "\n",
       "                                                    ana_Total accuracy  \\\n",
       "embeddings/baseline/WikiChinese/word/word2vec/s...            0.640084   \n",
       "embeddings/baseline/WikiChinese/word/word2vec/c...            0.534103   \n",
       "embeddings/baseline/WikiChinese/word/cwe/cb-it1...            0.101784   \n",
       "embeddings/baseline/WikiChinese/word/jwe/cb-it1...            0.405037   \n",
       "\n",
       "                                                    cls_score_mean  \n",
       "embeddings/baseline/WikiChinese/word/word2vec/s...        0.863717  \n",
       "embeddings/baseline/WikiChinese/word/word2vec/c...        0.927782  \n",
       "embeddings/baseline/WikiChinese/word/cwe/cb-it1...        0.945622  \n",
       "embeddings/baseline/WikiChinese/word/jwe/cb-it1...        0.897871  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(D).T[['sim240_spearman', 'sim297_spearman', 'ana_Total accuracy',  'cls_score_mean' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
