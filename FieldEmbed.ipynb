{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Field Embedding Naive Version `fieldembed_token_neg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORPUS\tread from pickle file : data/WikiTotal/word/Token447174/Pyramid/CORPUS.p\n",
      "CORPUS\tthe length of it is   : 1\n",
      "FOLDER\tread from pickle file : data/WikiTotal/word/Token447174/Pyramid/FOLDER.p\n",
      "FOLDER\tthe length of it is   : 1\n",
      "TEXT\tread from pickle file : data/WikiTotal/word/Token447174/Pyramid/TEXT.p\n",
      "TEXT\tthe length of it is   : 4717592\n",
      "SENT\tread from pickle file : data/WikiTotal/word/Token447174/Pyramid/SENT.p\n",
      "SENT\tthe length of it is   : 11199643\n",
      "TOKEN\tread from pickle file : data/WikiTotal/word/Token447174/Pyramid/TOKEN.p\n",
      "TOKEN\tthe length of it is   : 257789077\n",
      "**************************************** \n",
      "\n",
      "token\tread from pickle file : data/WikiTotal/word/Token447174/GrainUnique/token.p\n",
      "token\tthe length of it is   : 447174\n",
      "**************************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from nlptext.base import BasicObject\n",
    "from datetime import datetime\n",
    "from evals import Evaluation\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from fieldembed.models.fieldembed import FieldEmbedding\n",
    "\n",
    "D = {} # use to save the model result\n",
    "\n",
    "BOB = 'data/WikiTotal/word/Token447174/Pyramid/'\n",
    "LGU = 'data/WikiTotal/word/Token447174/GrainUnique/'\n",
    "\n",
    "BasicObject.INIT_FROM_PICKLE(BOB, LGU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mode =  'fieldembed_token'\n",
    "workers = 8\n",
    "size = 200\n",
    "batch_words = 10000\n",
    "alpha = 0.025\n",
    "sg = 1\n",
    "iter = 1\n",
    "\n",
    "sg_or_cbow = 'sg' if sg else 'cbow'\n",
    "\n",
    "s = datetime.now(); print('+++++Start++++++', s)\n",
    "# end = datetime.now(); print('+++++End++++++', end, 'Using:',e - s ); \n",
    "model = FieldEmbedding(nlptext = BasicObject, size = size, alpha = alpha, mode = mode,\n",
    "                          sg = sg, iter=iter, workers = workers, batch_words = batch_words)\n",
    "e = datetime.now(); time = e - s\n",
    "print('+++++End++++++', e, 'Using:', time); \n",
    "\n",
    "wv = model.wv\n",
    "evals = Evaluation(wv)\n",
    "\n",
    "s = datetime.now()\n",
    "d = evals.run_wv_lexical_evals()\n",
    "d['time'] = time\n",
    "e = datetime.now()\n",
    "print(e - s)\n",
    "\n",
    "D[mode+'_' + sg_or_cbow] = d\n",
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mode =  'fieldembed_token'\n",
    "workers = 8\n",
    "size = 200\n",
    "batch_words = 10000\n",
    "alpha = 0.025\n",
    "sg = 0\n",
    "iter = 1\n",
    "\n",
    "sg_or_cbow = 'sg' if sg else 'cbow'\n",
    "\n",
    "s = datetime.now(); print('+++++Start++++++', s)\n",
    "# end = datetime.now(); print('+++++End++++++', end, 'Using:',e - s ); \n",
    "model = FieldEmbedding(nlptext = BasicObject, size = size, alpha = alpha, mode = mode,\n",
    "                          sg = sg, iter=iter, workers = workers, batch_words = batch_words)\n",
    "e = datetime.now(); time = e - s\n",
    "print('+++++End++++++', e, 'Using:', time); \n",
    "\n",
    "wv = model.wv\n",
    "evals = Evaluation(wv)\n",
    "\n",
    "s = datetime.now()\n",
    "d = evals.run_wv_lexical_evals()\n",
    "d['time'] = time\n",
    "e = datetime.now()\n",
    "print(e - s)\n",
    "\n",
    "D[mode+'_' + sg_or_cbow] = d\n",
    "d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Field Embedding Single Channel `fieldembed_token_neg_0X1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORPUS\tread from pickle file : data/WikiTotal/word/Token447170/Pyramid/CORPUS.p\n",
      "CORPUS\tthe length of it is   : 1\n",
      "FOLDER\tread from pickle file : data/WikiTotal/word/Token447170/Pyramid/FOLDER.p\n",
      "FOLDER\tthe length of it is   : 1\n",
      "TEXT\tread from pickle file : data/WikiTotal/word/Token447170/Pyramid/TEXT.p\n",
      "TEXT\tthe length of it is   : 4717592\n",
      "SENT\tread from pickle file : data/WikiTotal/word/Token447170/Pyramid/SENT.p\n",
      "SENT\tthe length of it is   : 11199643\n",
      "TOKEN\tread from pickle file : data/WikiTotal/word/Token447170/Pyramid/TOKEN.p\n",
      "TOKEN\tthe length of it is   : 257789077\n",
      "**************************************** \n",
      "\n",
      "token\tread from pickle file : data/WikiTotal/word/Token447170/GrainUnique/token.voc\n",
      "token\tthe length of it is   : 447170\n",
      "**************************************** \n",
      "\n",
      "data/WikiTotal/word/Token447170\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from nlptext.base import BasicObject\n",
    "from datetime import datetime\n",
    "\n",
    "BOB = 'data/wiki/word/Token6905/Pyramid/'\n",
    "LGU = 'data/wiki/word/Token6905/GrainUnique/'\n",
    "\n",
    "BOB = 'data/WikiTotal/word/Token447170/Pyramid/'\n",
    "LGU = 'data/WikiTotal/word/Token447170/GrainUnique/'\n",
    "\n",
    "BasicObject.INIT_FROM_PICKLE(BOB, LGU)\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "from nlptext.corpus import Corpus\n",
    "\n",
    "\n",
    "corpus = Corpus()\n",
    "print(corpus.TokenNum_Dir)\n",
    "\n",
    "#if os.path.isdir(corpus.Channel_Dir):\n",
    "#    shutil.rmtree(corpus.Channel_Dir)\n",
    "\n",
    "\n",
    "CHANNEL_SETTINGS_TEMPLATE = {\n",
    "    # CTX_IND\n",
    "    'token':   {'use': True, 'Max_Ngram': 1,},\n",
    "    'char':    {'use': True,'Max_Ngram': 1, 'end_grain': False},\n",
    "    'pinyin':   {'use': True,'Max_Ngram': 2, 'end_grain': False},\n",
    "    'subcomp': {'use': True,'Max_Ngram': 3, 'end_grain': True},\n",
    "    'stroke':  {'use': True,'Max_Ngram': 3, 'end_grain': True},\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deal with the Channel: char\n",
      "Current Channel is        \t char\n",
      "Current Channel Max_Ngram \t 1\n",
      "+++++Start++++++ 2019-06-14 15:17:21.511987\n",
      "!!!======== Build_vocab based on NLPText....\n",
      "-------> Prepare Vocab....\n",
      "o--> Get Vocab Frequency from NLPText\n",
      "o--> Prepare WV's index2word, vocab...\n",
      "\tStart:  2019-06-14 15:17:21.516278\n",
      "\tEnd  :  2019-06-14 15:17:22.388518\n",
      "\tTotal Time: 0:00:00.872240\n",
      "o--> Compute Token's sampel_int...\n",
      "\tStart:  2019-06-14 15:17:22.388950\n",
      "\tEnd  :  2019-06-14 15:17:23.424333\n",
      "\tTotal Time: 0:00:01.035383\n",
      "o--> Compute Cum Table\n",
      "\tStart:  2019-06-14 15:17:23.424733\n",
      "\tEnd  :  2019-06-14 15:17:24.135451\n",
      "\tTotal Time: 0:00:00.710718\n",
      "-------> Prepare Field Info....\n",
      "Get LookUp Table for Channel: char\n",
      "{'token': 0}\n",
      "{'token': ['char']}\n",
      "[[0, None]]\n",
      "[[[<fieldembed.models.keyedvectors.Word2VecKeyedVectors object at 0x7f2abfb14cc0>,\n",
      "   array([   0,    1,    2, ..., 2115, 2950, 2837], dtype=uint32),\n",
      "   array([      1,       2,       3, ..., 1376236, 1376239, 1376241],\n",
      "      dtype=uint32),\n",
      "   array([1.        , 1.        , 1.        , ..., 0.25      , 0.33333334,\n",
      "       0.5       ], dtype=float32),\n",
      "   43]]]\n",
      "char (0, 200)\n",
      "use_head: 0 use_sub: 1\n",
      "-------> Prepare Trainable Weight....\n",
      "o--> Prepare Trainable Parameters\n",
      "\tStart:  2019-06-14 15:17:24.675157\n",
      "init neg with 0\n",
      "char (7049, 200)\n",
      "use_head: 0 use_sub: 1\n",
      "\tEnd  :  2019-06-14 15:17:24.743577\n",
      "\tTotal Time: 0:00:00.068420\n",
      "======== The Voc and Parameters are Ready!\n",
      "======== Total Time:  0:00:03.231516\n",
      "\n",
      "\n",
      "======== Training Start ....\n",
      "257789077\n",
      "Start getting batch infos\n",
      "2019-06-14 15:17:24.743956\n",
      "Read info from: data/WikiTotal/word/Token447170/Pyramid/10000_Info.p\n",
      "2019-06-14 15:17:24.760410\n",
      "The time of finding batch_end_st_idx_list: 0:00:00.016454\n",
      "Total job number is: 25779\n"
     ]
    }
   ],
   "source": [
    "selected_fields = ['char']\n",
    "mode =  'fieldembed_0X1_neat'\n",
    "workers = 8\n",
    "size = 200\n",
    "batch_words = 10000\n",
    "alpha = 0.025\n",
    "sg = 1\n",
    "iter = 1\n",
    "sg_or_cbow = 'sg' if sg else 'cbow'\n",
    "\n",
    "from fieldembed.models.fieldembed import FieldEmbedding\n",
    "from evals import Evaluation\n",
    "selected_fields_template = {k: v for k, v in CHANNEL_SETTINGS_TEMPLATE.items() if k in selected_fields}\n",
    "\n",
    "\n",
    "BasicObject.BUILD_GRAIN_UNI_AND_LOOKUP(selected_fields_template)\n",
    "# BasicObject.CHANNEL_SETTINGS\n",
    "\n",
    "s = datetime.now(); print('+++++Start++++++', s)\n",
    "# end = datetime.now(); print('+++++End++++++', end, 'Using:',e - s ); \n",
    "model = FieldEmbedding(nlptext = BasicObject, Field_Settings = BasicObject.CHANNEL_SETTINGS, size = size, alpha = alpha, mode = mode,\n",
    "                          sg = sg, iter=iter, workers = workers, batch_words = batch_words)\n",
    "e = datetime.now(); time = e - s\n",
    "print('+++++End++++++', e, 'Using:', time); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wv = model.wv_neg\n",
    "evals = Evaluation(wv)\n",
    "\n",
    "s = datetime.now()\n",
    "d = evals.run_wv_lexical_evals()\n",
    "d['time'] = time\n",
    "e = datetime.now()\n",
    "print(e - s)\n",
    "\n",
    "\n",
    "field_string = '_'.join(selected_fields)\n",
    "# D[mode+'_' + sg_or_cbow + '-' + field_string] = d\n",
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.7957134e-03,  1.5882452e-03, -1.8345740e-03, ...,\n",
       "         7.0323318e-04, -2.8051776e-04, -4.1422943e-04],\n",
       "       [ 1.6751538e-04, -1.0281407e-03,  1.9550940e-03, ...,\n",
       "        -3.1825245e-04, -9.7429648e-04, -1.2225709e-03],\n",
       "       [ 3.6580619e-04,  1.2770864e-03,  5.9722172e-04, ...,\n",
       "        -1.8381354e-03, -1.5183592e-03, -1.1817002e-03],\n",
       "       ...,\n",
       "       [ 3.5330435e-04, -2.2741035e-04,  4.5395125e-05, ...,\n",
       "        -6.9556073e-03, -2.4317824e-03, -1.0760780e-03],\n",
       "       [-4.0874197e-03,  1.2519490e-03, -4.8138105e-04, ...,\n",
       "        -1.2221847e-02, -7.9959555e-06,  1.3628692e-03],\n",
       "       [-3.5159409e-03, -1.5763045e-04, -3.1229379e-03, ...,\n",
       "        -4.5041861e-03,  4.9837609e-04,  2.2416171e-03]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Field Embedding Single Channel `fieldembed_token_neg_M0X1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Field Embedding Single Channel `fieldembed_token_neg_M0X2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Field Embedding Single Channel `fieldembed_token_neg_M0XY`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Field Embedding Single Channel `fieldembed_token_neg_M0XY_P`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
